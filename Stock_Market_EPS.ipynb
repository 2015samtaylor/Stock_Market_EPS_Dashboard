{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4208f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML('<style>.input, .jp-InputArea {display: none !important}</style>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a424bd",
   "metadata": {
    "code_folding": [
     25,
     38,
     66,
     118,
     141,
     166,
     196,
     234,
     289,
     325,
     352,
     403,
     439
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import alpha_vantage\n",
    "import csv\n",
    "import requests\n",
    "import warnings\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.stats as stats\n",
    "import requests\n",
    "import calendar\n",
    "from bs4 import BeautifulSoup\n",
    "warnings.simplefilter('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "api_key = ('QFZF2CEU5FAI6YIW')\n",
    "sym = input(\"Input your stock ticker: \")\n",
    "\n",
    "class calls:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_weekly_data():\n",
    "        \n",
    "        ts = TimeSeries(key= api_key, output_format = 'pandas')\n",
    "        df, meta_data = ts.get_weekly(symbol = sym.upper())\n",
    "\n",
    "        df.reset_index(inplace = True)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.rename(columns = {'date': 'reportedDate'}, inplace = True)\n",
    "        df = df.sort_values(by = 'reportedDate')\n",
    "        \n",
    "        return(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def merge_weekly_stock(frame, df, kicker): # merge stock earnings, with weekly data. Insert columns\n",
    "                \n",
    "        frame.sort_values(by = 'fiscalDateEnding', inplace = True)\n",
    "        \n",
    "        if kicker == 'TRUE':\n",
    "            frame.rename(columns = {'fiscalDateEnding': 'reportedDate'}, inplace = True)\n",
    "             #create Free Cash Flow \n",
    "            frame = frame.replace('None', 0)\n",
    "            frame['FreeCashFlow'] = frame['operatingCashflow'] - frame['capitalExpenditures']            \n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        new_df = pd.merge_asof(frame, df, on='reportedDate', direction='nearest')\n",
    "\n",
    "        # add in the most up to date stock price as the final column\n",
    "        end_stock_date = df['reportedDate'][0]\n",
    "        end_stock_val = df['4. close'][0]\n",
    "\n",
    "        # create the dict with to be the final row with proper date, & stock close. \n",
    "        keys = list(new_df.columns)\n",
    "        d = {key: None if key != '4. close' else end_stock_val for key in keys}\n",
    "        d['reportedDate']= end_stock_date\n",
    "        \n",
    "        new_df = new_df.append(d, ignore_index = True)\n",
    "        \n",
    "        return(new_df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def statement(statement):\n",
    "        \n",
    "        url = f'https://www.alphavantage.co/query?function={statement}&symbol={sym.upper()}&apikey={api_key}'\n",
    "    \n",
    "        if statement == 'CASH_FLOW':\n",
    "    \n",
    "            r = requests.get(url)\n",
    "\n",
    "            if r.status_code == 200:\n",
    "                try:\n",
    "                    cf_annual = pd.DataFrame(r.json()['annualReports'])\n",
    "                except:\n",
    "                    print('Annual Reports do not exist in cash flow call')\n",
    "                try:\n",
    "                    cf_quarterly = pd.DataFrame(r.json()['quarterlyReports'])\n",
    "                except:\n",
    "                    print('Quarterly Reports do not exist in cash flow call')\n",
    "                    \n",
    "\n",
    "                cf_quarterly[['paymentsForRepurchaseOfCommonStock', 'capitalExpenditures', 'operatingCashflow']] = cf_quarterly[['paymentsForRepurchaseOfCommonStock', 'capitalExpenditures', 'operatingCashflow']].replace('None', 0)\n",
    "                cf_annual[['paymentsForRepurchaseOfCommonStock', 'capitalExpenditures', 'operatingCashflow']] = cf_annual[['paymentsForRepurchaseOfCommonStock', 'capitalExpenditures', 'operatingCashflow']].replace('None', 0)\n",
    "                        \n",
    "                return(cf_annual, cf_quarterly)\n",
    "            \n",
    "        elif statement == 'EARNINGS':\n",
    "            \n",
    "                r = requests.get(url)\n",
    "                data = r.json()\n",
    "\n",
    "                if statement == 'EARNINGS':\n",
    "                    annual = pd.DataFrame(data['annualEarnings'])\n",
    "                    quarterly = pd.DataFrame(data['quarterlyEarnings'])\n",
    "                    annual['weekly'] = annual['fiscalDateEnding'].str[:7]\n",
    "                    quarterly['weekly'] = quarterly['reportedDate'].str[:7]\n",
    "                else:    \n",
    "                    annual = pd.DataFrame(data['annualReports'])\n",
    "                    quarterly = pd.DataFrame(data['quarterlyReports'])\n",
    "\n",
    "\n",
    "                # For rows with none replace with np.nan. Then replace 'reportedEPS' with 'estimatedEPS' if NaN. \n",
    "                quarterly = quarterly.replace('None', np.nan)\n",
    "                quarterly['estimatedEPS'].fillna(quarterly['reportedEPS'], inplace=True)\n",
    "                annual = annual.replace('None', np.nan)     \n",
    "                \n",
    "                quarterly['reportedEPS'] = quarterly['reportedEPS'].astype(float)\n",
    "                \n",
    "                quarterly['reportedEPS_diff'] = quarterly['reportedEPS'].diff()\n",
    "#                 annual['reportedEPS_diff'] = annual['reportedEPS'].diff()\n",
    "\n",
    "                return(annual, quarterly)  #get data via alpha vantage API\n",
    "        \n",
    "    @staticmethod   \n",
    "    def fix_dtypes(frame):\n",
    "                        \n",
    "        #change date_cols to datetime using regex\n",
    "        date_cols = list(frame.filter(regex=re.compile('date', re.IGNORECASE)).columns)\n",
    "        \n",
    "#         if (frame.equals(cf_quarterly)) or (frame.equals(cf_annual)):\n",
    "#             frame[['paymentsForRepurchaseOfCommonStock', 'capitalExpenditures', 'operatingCashflow']] = frame[['paymentsForRepurchaseOfCommonStock', 'capitalExpenditures', 'operatingCashflow']].replace('None', 0)\n",
    "#         else:\n",
    "#             pass\n",
    "        \n",
    "        for i in date_cols:\n",
    "            frame[i] = pd.to_datetime(frame[i])\n",
    "        \n",
    "        #get remaining columns try to change to float, if error occurs then assume a string\n",
    "        other_cols = list(set(frame.columns) - set(date_cols))\n",
    "\n",
    "        for i in other_cols:\n",
    "            try:\n",
    "                frame[i] = frame[i].astype(float)\n",
    "            except ValueError:\n",
    "                frame[i] = frame[i].astype(str) # fix data types from the API call\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape_splits():  # webscrape historical stock splits from said stock. \n",
    "        session = requests.Session()\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',}\n",
    "        url = 'https://www.stocksplithistory.com/?symbol={}'.format(sym.upper())\n",
    "        response = session.get(url, headers= headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'class': 'split-history-table'})\n",
    "        td_tags = soup.find_all('td', {'align': 'center', 'style': 'padding: 4px; border-bottom: 1px solid #CCCCCC'})\n",
    "\n",
    "\n",
    "        date_list = []\n",
    "        split_list = []\n",
    "\n",
    "        for i in range(0, len(td_tags), 2):\n",
    "            date = td_tags[i].text.strip()\n",
    "            split = td_tags[i+1].text.strip()\n",
    "            date_list.append(date)\n",
    "            split_list.append(split)\n",
    "\n",
    "        splits = pd.DataFrame({'Date': date_list, 'Split': split_list})\n",
    "        splits['Date'] = pd.to_datetime(splits['Date'])\n",
    "        splits_filt = splits.loc[splits['Date'] > '01/01/2000']\n",
    "        return(splits_filt)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize_stock_splits(df, scrape): #normalize the dataframe. \n",
    "\n",
    "        i = 0\n",
    "        while i < len(scrape):   \n",
    "\n",
    "            split_string = list(scrape['Split'].values)[i]\n",
    "            split_list = split_string.split(\"for\")\n",
    "            split_ratio = int(split_list[0].strip())\n",
    "\n",
    "            split_date = scrape['Date'].values[i]\n",
    "            split_date = pd.to_datetime(split_date)\n",
    "\n",
    "            #filter for current week up to split & everything prior. \n",
    "            mask = ((df['reportedDate'].dt.year < split_date.year) | \n",
    "                ((df['reportedDate'].dt.year == split_date.year) & (df['reportedDate'].dt.week <= split_date.week)))\n",
    "            split_df = df.loc[mask]\n",
    "\n",
    "\n",
    "            split_df['1. open'] = split_df['1. open'] / split_ratio\n",
    "            split_df['2. high'] = split_df['2. high'] / split_ratio\n",
    "            split_df['3. low'] = split_df['3. low'] / split_ratio\n",
    "            split_df['4. close'] = split_df['4. close'] / split_ratio\n",
    "\n",
    "\n",
    "            df.update(split_df)\n",
    "            i += 1\n",
    "        \n",
    "        return(df)\n",
    "            \n",
    "    @staticmethod\n",
    "    def plot_EPS_stock():\n",
    "        fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "        ax2 = ax1.twinx()\n",
    "\n",
    "        # plot the first line with the left y-axis\n",
    "        sns.lineplot(x='reportedDate', y='reportedEPS', data=df_merged, ax=ax1, color='orange', label='reportedEPS')\n",
    "\n",
    "        # plot the second line with the left y-axis\n",
    "        sns.lineplot(x='reportedDate', y='estimatedEPS', data=df_merged, ax=ax1, color='red', label='estimatedEPS')\n",
    "\n",
    "        # plot the third with the right y-axis\n",
    "        sns.lineplot(x='reportedDate', y='4. close', data=df_merged, color='green', label='Stock Price')\n",
    "\n",
    "        ax1.set_xlabel('')\n",
    "        ax1.set_ylabel('Earnings Per Share', fontsize=25)\n",
    "        ax2.set_ylabel('Stock Price', fontsize=25)\n",
    "        ax1.set_title('EPS & Stock Price', fontsize=25)\n",
    "\n",
    "        # adjust the position of the legends\n",
    "        legend1 = ax1.legend(loc='upper left', fontsize='x-large')\n",
    "        legend2 = ax2.legend(loc='upper right', fontsize='x-large')\n",
    "\n",
    "        # set zorder to bring the legends to the front\n",
    "        legend1.set_zorder(100)\n",
    "        legend2.set_zorder(100)\n",
    "\n",
    "        last_date = df_merged['reportedDate'].iloc[-3]\n",
    "        ax1.axvline(x=last_date, linestyle='dotted', color='black')\n",
    "\n",
    "        ax1.invert_yaxis()\n",
    "\n",
    "        # show the grid lines behind the legends\n",
    "        ax1.grid(True, linestyle='dotted', zorder=0)\n",
    "        ax2.grid(True, linestyle='dotted', zorder=0)\n",
    "\n",
    "        plt.show()  # EPS vs Stock Plot #plot EPS, vs stock price weekly \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_next_numbers():  #scraping future earnings\n",
    "    \n",
    "        session = requests.Session()\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',}\n",
    "\n",
    "        url = 'https://www.zacks.com/stock/quote/{}/detailed-earning-estimates'.format(sym.upper())\n",
    "        response = session.get(url, headers = headers)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        tags = soup.find_all('a', href='/stock/chart/{}/price-consensus-eps-surprise-chart'.format(sym.upper()))\n",
    "\n",
    "        number_values = []\n",
    "        for tag in tags:\n",
    "            text = tag.text\n",
    "            number_values.append(text)\n",
    "\n",
    "        t = soup.find_all('th', {'class': ''})\n",
    "\n",
    "        tag_list = []\n",
    "        for tags in t:\n",
    "            tag_list.append(tags.text)\n",
    "\n",
    "        t = pd.DataFrame(tag_list, columns = ['Tags'])\n",
    "        t = pd.DataFrame(t['Tags'].drop_duplicates())\n",
    "        t = t[t['Tags'].str.contains('Qtr|Year')]\n",
    "\n",
    "        frame = {'Revenue': number_values[1:5],\n",
    "                'EPS': number_values[6:10]}\n",
    "\n",
    "        index = list(t['Tags'][0:4].values)\n",
    "        scrape = pd.DataFrame(frame, index=index)\n",
    "        #---------------------------------------\n",
    "\n",
    "        tds = soup.find_all('td', {'class': 'alpha'})\n",
    "\n",
    "        data = []       \n",
    "        for td in tds:\n",
    "            row = {}\n",
    "            if td.text == 'Current' or td.text == '7 Days Ago' or td.text == '30 Days Ago' or td.text == '60 Days Ago' or td.text == '90 Days Ago':\n",
    "                row['Period'] = td.text\n",
    "                row['Value1'] = td.find_next_siblings('td')[0].text\n",
    "                row['Value2'] = td.find_next_siblings('td')[1].text\n",
    "                row['Value3'] = td.find_next_siblings('td')[2].text\n",
    "                row['Value4'] = td.find_next_siblings('td')[3].text\n",
    "                data.append(row)\n",
    "\n",
    "        consensus = pd.DataFrame(data)\n",
    "        consensus.set_index('Period', inplace = True)\n",
    "        col_dict = dict(zip(list(consensus.columns), index))\n",
    "        consensus = consensus.rename(columns = col_dict)\n",
    "\n",
    "        return(scrape, consensus)\n",
    "    \n",
    "    @staticmethod\n",
    "    def insert_proj_EPS(current_or_next, frame, proj): #insert projected EPS\n",
    "    \n",
    "        #get the last record of earnings quarterly and offset by 3 months\n",
    "        fiscal_val = frame.iloc[len(frame) -1]['fiscalDateEnding']\n",
    "        reported_val = frame.iloc[len(frame) -1]['reportedDate']\n",
    "        offset = pd.DateOffset(months = 3)\n",
    "\n",
    "        fiscal_date_end = fiscal_val+offset\n",
    "        reported_date_end = reported_val + offset\n",
    "\n",
    "        if current_or_next == 'current':\n",
    "            qtr = proj['EPS'][0]\n",
    "        elif current_or_next == 'next':\n",
    "            qtr = proj['EPS'][1]\n",
    "        else:\n",
    "            print('Error with naming convention')\n",
    "\n",
    "\n",
    "        first_row = pd.DataFrame({\n",
    "            'fiscalDateEnding': [fiscal_date_end],\n",
    "            'reportedDate': [reported_date_end],\n",
    "            'reportedEPS': [None],\n",
    "            'estimatedEPS': [qtr],\n",
    "            'surprise': [0],\n",
    "            'surprisePercentage': [0],\n",
    "            'weekly': ['2023']\n",
    "        })\n",
    "\n",
    "        if current_or_next == 'current':\n",
    "            frame.loc[-1] = first_row.iloc[0]\n",
    "        elif current_or_next == 'next':\n",
    "            frame.loc[-2] = first_row.iloc[0]\n",
    "        else:\n",
    "            print('Error with row update')\n",
    "            \n",
    "    @staticmethod\n",
    "    def estimates(consensus, quarter_or_annual):  #linechart of consensus estimates EPS\n",
    "    \n",
    "        consensus[list(consensus.columns)] = consensus[list(consensus.columns)].astype(float)\n",
    "\n",
    "        if quarter_or_annual == 'quarter':\n",
    "            consensus = consensus.iloc[:, :2]\n",
    "        elif quarter_or_annual == 'annual':\n",
    "            consensus = consensus.iloc[:, 2:4]\n",
    "        else:\n",
    "            print('wrong input')\n",
    "\n",
    "        sns.set(style=\"darkgrid\")\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        ax = sns.lineplot(data=consensus,linewidth=3.0)\n",
    "\n",
    "        ax.invert_xaxis()\n",
    "\n",
    "        # Set the title and labels\n",
    "        plt.title(f'{quarter_or_annual.upper()} EPS Consensus Trends', fontsize = 25)\n",
    "        plt.xlabel('Date', fontsize = 25)\n",
    "        plt.ylabel('EPS', fontsize = 25)\n",
    "        plt.legend(fontsize='x-large', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "        # Display the chart\n",
    "        plt.show()\n",
    "        \n",
    "    @staticmethod\n",
    "    def EPS_frame():\n",
    "\n",
    "        df_merged.set_index('reportedDate', inplace=True)\n",
    "        EPS_frame = df_merged.loc[:, ['reportedEPS', 'estimatedEPS']]\n",
    "\n",
    "        # get the projections for next quarter to assume the empty spaces. \n",
    "        EPS_frame['reportedEPS'] = EPS_frame['reportedEPS'].fillna(EPS_frame['estimatedEPS'])\n",
    "        EPS_frame = EPS_frame[['reportedEPS']]\n",
    "        EPS_frame['reportedEPS'] = EPS_frame['reportedEPS'].astype(float)\n",
    "\n",
    "        EPS_frame['percentage_change'] = EPS_frame.pct_change(periods=4)\n",
    "\n",
    "        # Identify the indices where the reportedEPS changed from negative to positive\n",
    "        positive_indices = EPS_frame.loc[(EPS_frame['reportedEPS'] > 0) & (EPS_frame['reportedEPS'].shift(4) < 0)].index\n",
    "        # Update the percentage_change column to be positive for the identified indices\n",
    "        EPS_frame.loc[positive_indices, 'percentage_change'] = EPS_frame.loc[positive_indices, 'percentage_change'].abs()\n",
    "\n",
    "        EPS_frame['percentage_change'] = EPS_frame['percentage_change'] * 100\n",
    "        EPS_frame['percentage_change'] = EPS_frame['percentage_change'].round(2) \n",
    "        EPS_frame_ = EPS_frame\n",
    "        EPS_frame = EPS_frame[::-1]\n",
    "        EPS_frame = EPS_frame.transpose()\n",
    "        display(EPS_frame)\n",
    "        return(EPS_frame_)\n",
    "    \n",
    "    @staticmethod\n",
    "    def average_best_EPS():\n",
    "        \n",
    "        EPS_frame['quarter_groupings'] = EPS_frame.reset_index().index % 4 + 1\n",
    "        grouped = EPS_frame.groupby('quarter_groupings')    \n",
    "\n",
    "        result_df = pd.DataFrame(columns=['Month', 'EPS_mean'])  # Create an empty DataFrame\n",
    "\n",
    "        for num in range(1, 5):\n",
    "\n",
    "            sub = grouped.get_group(num)\n",
    "            EPS_mean = round(sub['reportedEPS'].mean(), 2)\n",
    "            month_name = calendar.month_name[sub.index.month.value_counts().idxmax()]\n",
    "\n",
    "            result_df = result_df.append({'Month': month_name, 'EPS_mean': EPS_mean}, ignore_index=True)\n",
    "\n",
    "        text = 'All Time Quarterly EPS Averages:'\n",
    "        formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "        print(f\"{formatted_text}\")\n",
    "        \n",
    "        result_df['Month_Number'] = pd.to_datetime(result_df['Month'], format='%B').dt.month\n",
    "        result_df = result_df.sort_values(by = 'Month_Number')\n",
    "        result_df = result_df.set_index('Month')\n",
    "        display(result_df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_EPS_hbar(df):\n",
    "\n",
    "        # Set the figure size and create subplots\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "        # Plot the horizontal bars with customized colors\n",
    "        bars = ax.barh(df.index, df['reportedEPS'], color='black', edgecolor='black', linewidth=0.8)\n",
    "\n",
    "        # Set the labels and title\n",
    "        ax.set_xlabel('Reported EPS', fontsize=25)\n",
    "        ax.set_ylabel('Reported Date', fontsize=20)\n",
    "        ax.set_title('Reported EPS by Period', fontsize=25 )\n",
    "\n",
    "        # Add data labels to the bars\n",
    "        for bar in bars:\n",
    "            value = bar.get_width()\n",
    "            x = value\n",
    "            if value < 0:\n",
    "                x = 0\n",
    "                ax.text(value, bar.get_y() + bar.get_height() / 2, f'{value:.2f}', va='center', ha='right', color='black')\n",
    "            else:\n",
    "                ax.text(value, bar.get_y() + bar.get_height() / 2, f'{value:.2f}', va='center', ha='left', color='black')\n",
    "\n",
    "        # Customize the plot background color\n",
    "        ax.set_facecolor('lightgray')\n",
    "\n",
    "        # Customize the ticks and grid lines\n",
    "        ax.tick_params(axis='both', colors='black')\n",
    "        ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "        # Display the plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "# -----------------------------------------------------------------------------------------------------------------------           \n",
    "    \n",
    "def process_data(statement):   \n",
    "    # load the initial data into the frames\n",
    "    \n",
    "    if statement == 'CASH_FLOW':\n",
    "    \n",
    "        df = calls.get_weekly_data()\n",
    "        cf_annual, cf_quarterly = calls.statement(statement)\n",
    "\n",
    "        # fix data types in place\n",
    "        calls.fix_dtypes(cf_annual)\n",
    "        calls.fix_dtypes(cf_quarterly)  \n",
    "\n",
    "        # scrape and normalize stock splits\n",
    "        scrape = calls.scrape_splits()\n",
    "        df = calls.normalize_stock_splits(df, scrape)\n",
    "        df_merge = calls.merge_weekly_stock(cf_quarterly, df, 'TRUE')\n",
    "        \n",
    "        return(df_merge, df)\n",
    "        \n",
    "    elif statement == 'EARNINGS':\n",
    "        \n",
    "        df = calls.get_weekly_data()\n",
    "        earnings_annual, earnings_quarterly = calls.statement(statement)\n",
    "\n",
    "        calls.fix_dtypes(earnings_annual)\n",
    "        calls.fix_dtypes(earnings_quarterly)\n",
    "\n",
    "        scrape = calls.scrape_splits()\n",
    "        df = calls.normalize_stock_splits(df, scrape)\n",
    "        df_merged = calls.merge_weekly_stock(earnings_quarterly, df, 'FALSE')\n",
    "        \n",
    "        #drop last row with close data\n",
    "        df_merged = df_merged.drop(len(df_merged) - 1)\n",
    "        df_merged['reportedEPS_diff'] = df_merged['reportedEPS'].diff()\n",
    "        \n",
    "        proj, consensus = calls.get_next_numbers()\n",
    "        \n",
    "        calls.insert_proj_EPS('current', df_merged, proj)\n",
    "        calls.insert_proj_EPS('next', df_merged, proj)   \n",
    "        \n",
    "        df_merged.at[-1, '4. close'] = df.at[0, '4. close']\n",
    "        \n",
    "        return(df_merged, df, proj, consensus)\n",
    "    \n",
    "    else:\n",
    "        print(\"issue\")\n",
    "    \n",
    "    \n",
    "df_merged, df_2, proj, consensus = process_data('EARNINGS')\n",
    "df_merged_2, df_2_ = process_data('CASH_FLOW')\n",
    "    \n",
    "text = f\"\\n\\n\\nLast reported EPS: {df_merged.iloc[-3]['reportedEPS']} on {str(df_merged.iloc[-3]['reportedDate'])[:10]}\"\n",
    "formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "print(f\"{formatted_text}\")\n",
    "\n",
    "display(proj)\n",
    "calls.plot_EPS_stock()\n",
    "EPS_frame = calls.EPS_frame()\n",
    "calls.plot_EPS_hbar(EPS_frame)\n",
    "calls.average_best_EPS()\n",
    "\n",
    "print('\\n\\n\\n\\n\\n\\n\\n\\n ')\n",
    "\n",
    "text = 'EPS Consensus Trends'\n",
    "formatted_text = \"\\033[1;4m{}\\033[0m\".format(text) \n",
    "print(f'{formatted_text}')\n",
    "display(consensus)\n",
    "calls.estimates(consensus, 'quarter')\n",
    "calls.estimates(consensus, 'annual')\n",
    "\n",
    "# rather than having the mean for quarterly EPS averages. DO a box plot. \n",
    "# Confirm Quarterly EPS Averages Months are correct. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d6671",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def EPS_cycle():\n",
    "    sub = df_merged[['fiscalDateEnding', '4. close', 'reportedEPS', 'reportedEPS_diff']]\n",
    "    sub['reportedEPS'] = sub['reportedEPS'].astype(float)\n",
    "\n",
    "    output = sub.groupby(sub['fiscalDateEnding'].dt.month)[['reportedEPS_diff']].mean()\n",
    "    output.reset_index(inplace =True)\n",
    "    return(output)\n",
    "\n",
    "# ----------------------------------------------------------------------Show subplot of YoY EPS---------------------------\n",
    "\n",
    "def plot_change(column):\n",
    "    \n",
    "    frame = df_merged\n",
    "    frame['year'] = frame['fiscalDateEnding'].dt.year\n",
    "    years = list(frame['fiscalDateEnding'].dt.year.unique())\n",
    "\n",
    "    # Calculate the number of rows and columns needed based on the number of years\n",
    "    n_rows = (len(years) - 1) // 3 + 1\n",
    "    n_cols = min(len(years), 6)\n",
    "\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(15, 2*n_rows))\n",
    "\n",
    "    # Loop over the subplots and plot each year's data\n",
    "    for i, n in enumerate(years):\n",
    "        subset = frame.loc[frame['fiscalDateEnding'].dt.year == years[i]]\n",
    "\n",
    "        row = i // n_cols\n",
    "        col = i % n_cols\n",
    "    \n",
    "        sns.lineplot(data=subset, x='reportedDate', y=column,  ax=axs[row, col])\n",
    "        #sns.scatterplot(data=subset, x='reportedDate', y=column, ax=axs[row, col], s=50, linewidth=1, edgecolor='black', zorder=3)\n",
    "        axs[row, col].set_title(years[i])\n",
    "        axs[row, col].set_xlabel(None)\n",
    "        axs[row, col].set_ylabel(None)\n",
    "        axs[row, col].set_xticklabels(axs[row, col].get_xticklabels(), rotation=45)\n",
    "\n",
    "#     Remove any unused subplots\n",
    "    for i in range(len(years), n_rows * n_cols):\n",
    "        row = i // n_cols\n",
    "        col = i % n_cols\n",
    "        fig.delaxes(axs[row, col])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------Correlation Average-------------------------------------\n",
    "\n",
    "def correlation_average():\n",
    "\n",
    "    years = list(df_merged['fiscalDateEnding'].dt.year.unique())\n",
    "\n",
    "    for i in years:\n",
    "            small = df_merged.loc[df_merged['fiscalDateEnding'].dt.year == i]\n",
    "            small['reportedEPS_diff'] = small['reportedEPS_diff'].astype(float)\n",
    "            try:\n",
    "                out[str(i)] = small['reportedEPS_diff'].values\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    corr_list = []\n",
    "    year_list = []\n",
    "\n",
    "    for year in years:\n",
    "            try:\n",
    "\n",
    "                correlation, p_value = stats.pearsonr(out['reportedEPS_diff'], out[str(year)])\n",
    "                corr_list.append(correlation)\n",
    "                year_list.append(year)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    corr_frame = pd.DataFrame(corr_list, index=year_list, columns=['EPS correlation YoY'])\n",
    "\n",
    "    text = ('Earnings Cycle Correlation, takes the difference in EPS from Quarter to Quarter and compares YoY correlation')\n",
    "    formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "    print(f\"{formatted_text}\")\n",
    "\n",
    "    a = [x for x in corr_list if not math.isnan(x)]\n",
    "\n",
    "    # test correlation for most recent 60% or results\n",
    "    portion = round(.60 * len(a))\n",
    "    a_portion = [a[int(portion):]]\n",
    "    a_portion = [item for sublist in a_portion for item in sublist]\n",
    "\n",
    "    a = (sum(a) / len(a))\n",
    "    a_portion = (sum(a_portion) / len(a_portion))\n",
    "\n",
    "    text = (f'\\nAverage correlation value for all years {round(a, 2)}')\n",
    "    formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "    print(f\"{formatted_text}\")\n",
    "\n",
    "    text = (f'Average correlation value of last {str(int(portion))} years: {round(a_portion, 2)}')\n",
    "    formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "    print(f\"{formatted_text}\")\n",
    "    \n",
    "    display(corr_frame)\n",
    "    \n",
    "    text = ('\\n** Actual EPS results typically announced 1 month after fiscal date end **')\n",
    "    formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "    print(f\"{formatted_text}\")\n",
    "\n",
    "#--------------------------------------------------------------CASH FLOWS-------------------------------------------------\n",
    "\n",
    "def cash_flows():\n",
    "    df_sub = df_merged_2[['reportedDate', 'operatingCashflow', 'cashflowFromInvestment', 'cashflowFromFinancing', 'FreeCashFlow']]\n",
    "    # Remove the last row with NaN values\n",
    "    df_sub = df_sub[:-1]\n",
    "    # Melt the dataframe to create a long-form dataframe\n",
    "    df_long = pd.melt(df_sub, id_vars=['reportedDate'], var_name='Cash Flow', value_name='Amount')\n",
    "    # Create the bar chart using matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(24, 18))\n",
    "    df_long.pivot(index='reportedDate', columns='Cash Flow', values='Amount').plot(kind='bar', ax=ax)\n",
    "    # Add axis labels and a title\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel(\"Amount\", fontsize=25)\n",
    "    plt.title(\"Cash Flows Over Time\", fontsize=25)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=20)\n",
    "    ax.legend(fontsize='x-large')\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    df_merged_2['4. close'].plot(ax=ax2, color='gray', alpha=0.5, label='Stock Price')  # Include label for legend\n",
    "    ax2.set_ylabel(\"Stock Price\", fontsize=25)\n",
    "\n",
    "    # Combine the legends from both axes\n",
    "    handles1, labels1 = ax.get_legend_handles_labels()\n",
    "    handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(handles1 + handles2, labels1 + labels2, fontsize='x-large')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    df_sub.set_index('reportedDate', inplace=True)\n",
    "    cf_df = df_sub.loc[:, 'operatingCashflow':'FreeCashFlow']\n",
    "    cf_yoy_df = cf_df.pct_change(periods=4)\n",
    "    cf_yoy_df.columns = [col + '_YoY' for col in cf_yoy_df.columns]\n",
    "\n",
    "    display(cf_yoy_df)\n",
    "\n",
    "\n",
    "out = EPS_cycle()\n",
    "sns.barplot(x='fiscalDateEnding', y='reportedEPS_diff', data=out)\n",
    "plt.title('Average EPS Difference QoQ', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "\n",
    "correlation_average()  \n",
    "plot_change('reportedEPS_diff')\n",
    "\n",
    "cash_flows()\n",
    "\n",
    "\n",
    "# Change the percentages in cash flows over time\n",
    "# 2023 should still be plotted despite incomplete data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71bf746",
   "metadata": {},
   "source": [
    "# Cash Flow From Invesment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44def82",
   "metadata": {},
   "source": [
    "Cash flow from investments refers to the amount of cash inflow or outflow generated from a company's investments in assets, such as property, equipment, securities, or other investments. Here are some examples of cash flow from investment:\n",
    "\n",
    "Purchase of property: When a company purchases a property, the cash outflow from the investment will be recorded as a negative cash flow from investment.\n",
    "\n",
    "Sale of property: When a company sells a property, the cash inflow from the sale will be recorded as a positive cash flow from investment.\n",
    "\n",
    "Purchase of equipment: When a company purchases new equipment, the cash outflow from the investment will be recorded as a negative cash flow from investment.\n",
    "\n",
    "Sale of equipment: When a company sells equipment, the cash inflow from the sale will be recorded as a positive cash flow from investment.\n",
    "\n",
    "Purchase of securities: When a company purchases securities, such as stocks or bonds, the cash outflow from the investment will be recorded as a negative cash flow from investment.\n",
    "\n",
    "Sale of securities: When a company sells securities, the cash inflow from the sale will be recorded as a positive cash flow from investment.\n",
    "\n",
    "Dividend income: When a company receives dividends from its investments, the cash inflow from the dividend income will be recorded as a positive cash flow from investment.\n",
    "\n",
    "Interest income: When a company receives interest on its investments, the cash inflow from the interest income will be recorded as a positive cash flow from investment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bafa1c",
   "metadata": {},
   "source": [
    "# Cash Flow From Financing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a44f2",
   "metadata": {},
   "source": [
    "Cash flow from financing refers to the inflow and outflow of cash resulting from a company's financing activities, such as borrowing money, issuing stock, or paying dividends to shareholders. These activities affect the company's capital structure and the overall amount of debt and equity that the company holds.\n",
    "\n",
    "Here are some examples of cash flow from financing:\n",
    "\n",
    "Issuing new stock: When a company issues new shares of stock, the cash inflow from the sale of those shares is recorded as a positive cash flow from financing.\n",
    "\n",
    "Repurchasing stock: When a company buys back its own stock, the cash outflow from the repurchase is recorded as a negative cash flow from financing.\n",
    "\n",
    "Issuing debt: When a company borrows money through issuing bonds or taking out loans, the cash inflow from the debt issuance is recorded as a positive cash flow from financing.\n",
    "\n",
    "Repaying debt: When a company pays off its debt, the cash outflow from the repayment is recorded as a negative cash flow from financing.\n",
    "\n",
    "Paying dividends: When a company pays dividends to its shareholders, the cash outflow from the payment is recorded as a negative cash flow from financing.\n",
    "\n",
    "The net result of cash flow from financing activities can indicate whether a company is funding its operations through debt or equity, and whether it is generating enough cash to pay its obligations or requires additional financing to continue operating. Investors and analysts use this information to evaluate a company's financial health and investment potential.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
